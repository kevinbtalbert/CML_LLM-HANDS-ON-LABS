{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47c23c71",
   "metadata": {},
   "source": [
    "## Chroma Vector DB Usage\n",
    "#### Pre-requisites: User should run \"Populate Chroma Vector DB with document embeddings\" job so that Chroma has relevant embeddings before using this Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2717c30b",
   "metadata": {},
   "source": [
    "#### 5.5 Initialize persistent Chroma Vector DB connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b331a3ae-f63b-47c1-bfae-6e1efc5062b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Initialize a connection to the running Chroma DB server\n",
    "import chromadb\n",
    "import os\n",
    "\n",
    "## Use the following line to connect from within CML\n",
    "chroma_client = chromadb.PersistentClient(path=\"/home/cdsw/chroma-data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd98c00c",
   "metadata": {},
   "source": [
    "#### 5.6 Get Chroma Vector DB Collection and number of collection objects\n",
    "This code initializes a connection to Chroma DB, a database for managing and querying embeddings. It defines the embedding model to be used, specifies the name of the collection as 'cml-default', and attempts to get or create that collection with the specified embedding function. Finally, it retrieves and prints the total number of embeddings in the Chroma DB index, providing statistics on the collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4b448f4-877d-4854-9c17-9247441b5b4f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialising Chroma DB connection...\n",
      "Getting 'cml-default' as object...\n",
      "Success\n",
      "Total number of embeddings in Chroma DB index is 5\n"
     ]
    }
   ],
   "source": [
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "EMBEDDING_MODEL_REPO = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "EMBEDDING_MODEL_NAME = \"all-mpnet-base-v2\"\n",
    "EMBEDDING_FUNCTION = embedding_functions.SentenceTransformerEmbeddingFunction(model_name=EMBEDDING_MODEL_NAME)\n",
    "\n",
    "COLLECTION_NAME = 'cml-default'\n",
    "\n",
    "print(\"initialising Chroma DB connection...\")\n",
    "\n",
    "print(f\"Getting '{COLLECTION_NAME}' as object...\")\n",
    "try:\n",
    "    chroma_client.get_collection(name=COLLECTION_NAME, embedding_function=EMBEDDING_FUNCTION)\n",
    "    print(\"Success\")\n",
    "    collection = chroma_client.get_collection(name=COLLECTION_NAME, embedding_function=EMBEDDING_FUNCTION)\n",
    "except:\n",
    "    print(\"Creating new collection...\")\n",
    "    collection = chroma_client.create_collection(name=COLLECTION_NAME, embedding_function=EMBEDDING_FUNCTION)\n",
    "    print(\"Success\")\n",
    "\n",
    "# Get latest statistics from index\n",
    "current_collection_stats = collection.count()\n",
    "print('Total number of embeddings in Chroma DB index is ' + str(current_collection_stats))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b86cf4",
   "metadata": {},
   "source": [
    "#### 5.7 Sample demonstration of populating a vector into Chroma given several attributes\n",
    "\n",
    "Here we add a sample document with associated metadata and a unique ID to a Chroma vector database collection for semantic search, using the specified text content, classification, and file path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9e0835b3-87e3-4d67-abe2-6c6538f8f488",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Sample add to Chroma vector DB\n",
    "file_path = '/example/of/file/path/to/doc.txt'\n",
    "classification = \"public\"\n",
    "text = \"This is a sample document which would represent content for a semantic search.\"\n",
    "\n",
    "collection.add(\n",
    "    documents=[text],\n",
    "    metadatas=[{\"classification\": classification}],\n",
    "    ids=[file_path]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1193156d",
   "metadata": {},
   "source": [
    "#### 5.8 Sample demonstration of querying a vector in Chroma along with using metadata to reduce noise\n",
    "\n",
    "This code performs a semantic search in a Chroma vector database using sample query text and retrieves the two most similar results; metadata can be utilized to further refine search results by specifying filters based on metadata fields, allowing for more precise and context-aware queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5448a26",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ids': [['/home/cdsw/data/https:/docs.cloudera.com/machine-learning/cloud/architecture-overview/topics/ml-architecture-overview-cml.txt', '/home/cdsw/data/https:/docs.cloudera.com/machine-learning/cloud/product/topics/ml-product-overview.txt']], 'distances': [[1.4979395183284212, 1.5874341272395678]], 'metadatas': [[{'classification': 'public'}, {'classification': 'public'}]], 'embeddings': None, 'documents': [[\"CML ArchitectureCloudera Docs\\nCML Architecture\\nOnce a CML workspace is provisioned, you can start using Cloudera Machine Learning\\n      (CML) for your end-to-end Machine Learning workflow. \\nCML is a three-tier application that consists of a presentation tier, an application tier\\n         and a data tier. \\nWeb tier\\nCML is a web application that provides a UI that simplifies the action of managing\\n            workloads and resources for data scientists. It offers users a convenient way to deploy\\n            and scale their analytical pipeline and collaborate with their colleagues in a secure\\n            compartmentalized environment. \\nCML communicates using HTTPS, Websocket, and gRPC. External communication is limited to\\n            HTTP and Websocket for the web UI and APIs. In-cluster service-to-service communication\\n            uses gRPC and is encrypted and mutually authenticated using TLS (Transport Layer\\n            Security). \\n\\nApplication tier\\nThe application tier uses an actual set of workloads that users are running. These\\n            workloads are isolated in Kubernetes namespaces and run on specially marked compute\\n            nodes. Kubernetes/node level auto scaling is used to expand/contract the cluster size\\n            based on user demand.\\nUser code gets baked into Docker images via a set of Source-to-Image pods (S2I), which\\n            includes a managing server, a queue for builds, a registry that serves the images for\\n            Docker, a git server, and the builders that actually perform the image building.\\n            Traditionally these images used the host machine's docker, but CML switched to\\n            in-container builds for security and compliance on some platforms. \\n\\nData tier\\nCML uses an internal Postgres database for persisting metadata of user workloads such as\\n            Sessions, Jobs, Models and Applications, which runs as a pod and is backed by a\\n            persistent volume, using the cloud-provider's block storage offering (for example, EBS\\n            for AWS and Premium_LRS for Azure). \\nCML uses an NFS server, i.e. a POSIX-compliant file system, for storing users’ project\\n            files, which include user code, libraries installed into a Session, and small data\\n            files. For AWS, CML creates an Elastic File System (EFS) file system when provisioning\\n            the workspace for storing project files. For Azure, users can either provide an NFS\\n            volume created in Azure NetApp Files or an external NFS server when provisioning CML\\n            workspaces for storing project files. This NFS server is supplied to the CML workspaces\\n            as Kubernetes Persistent Volumes (PVs). Persistent Volume Claims (PVCs) are set up\\n            per-namespace, and each user gets their own namespace - thus each user’s view of the NFS\\n            server is limited to that exposed by the PVC. \\n\\n\\nParent topic: Architecture Overview\", \"Cloudera Machine Learning or CML Overview\\nCML is an abbreviation for Cloudera Machine Learning \\n\\nCloudera Machine Learning overview\\nMachine learning has become one of the most critical capabilities for modern businesses\\n    to grow and stay competitive today. From automating internal processes to optimizing the design,\\n    creation, and marketing processes behind virtually every product consumed, ML models have\\n    permeated almost every aspect of our work and personal lives.\\nML development is iterative and complex, made even harder because most ML tools aren’t built\\n      for the entire machine learning lifecycle. Cloudera Machine Learning on\\n      Cloudera Data Platform accelerates time-to-value by enabling data scientists to collaborate in\\n      a single unified platform that is all inclusive for powering any AI use case. Purpose-built\\n      for agile experimentation and production ML workflows, Cloudera Machine Learning manages everything from data preparation to MLOps,\\n      to predictive reporting. Solve mission critical ML challenges along the entire lifecycle with\\n      greater speed and agility to discover opportunities which can mean the difference for your\\n      business.\\nEach ML workspace enables teams of data scientists to develop, test, train, and ultimately\\n      deploy machine learning models for building predictive applications all on the data under\\n      management within the enterprise data cloud. ML workspaces support fully-containerized\\n      execution of Python, R, Scala, and Spark workloads through flexible and extensible engines. \\n\\n\\n\\n\\n\\nAI applications\\nAnalytical Applications provide a place to host long running applications within a CML\\n    project.\\nWhile CML offers a place for Data Scientists to perform advanced analytics and models into\\n      production, Analytical Applications provides a place to host long running applications within\\n      a CML project. This opens up a larger group of users to the insights discovered in CML.\\n      Applications can be built with a variety of frameworks like Flask and Streamlit. They run\\n      within their own isolated compute instance which keeps them from timing out and they take\\n      advantage of ML Runtimes. Applications are accessible to users through the web. Applications\\n      can be for a variety of use cases like hosting interactive data visualizations or providing a\\n      UI frontend for a deployed mode in CML. \\n\\n\\nExploratory Data Science\\nCML enables data practitioners to discover, query, and easily visualize their data sets\\n    all within a single user interface.\\nThe beginning of every data science project begins with finding and understanding the data\\n      you need. CML brings all the tools you need for exploratory data analysis together in a single\\n      UI so that data practitioners don't have to jump between applications, and IT doesn't have to\\n      support multiple tools. CML provides users with a view of available data assets that they can\\n      connect to, a sql editor to query those data sources, and an easy-to-use drag-and-drop\\n      visualization tool to understand your data and communicate insights.\\n\\n\\nML Ops\\nCML enables users to deploy machine learning and other models into\\n    production.\\nCML enables users to deploy machine learning and other models into production, either as a\\n      batch process through the Jobs functionality, or as near-real-time REST APIs using the Models\\n      functionality. In addition, CML provides a number of features to help maintain, monitor and\\n      govern these models in production. The Model Governance feature ensures that every deployed\\n      Model is tracked in the Cloudera Data Catalog, and allows the user to specify which data\\n      tables were used to train the model in order to provide model-data lineage. Deployed Models\\n      have a built-in dashboard for monitoring technical metrics relating to deployed CML Models,\\n      such as request throughput, latency, and resource consumption. Additionally, users can track\\n      arbitrary business metrics relating to each inference event, and match the results with\\n      delayed metrics from a data warehouse or other source using an automatically generated UUID.\\n      By analyzing these metrics, the user can assess the model for aggregated metrics such as\\n      accuracy on an ongoing basis.\\n\\n\\nCore capabilities\\nThis section details the core capabilities for Cloudera Machine Learning.\\nCloudera Machine Learning covers the end-to-end machine learning workflow,\\n      enabling fully isolated and containerized workloads - including Python, R, and\\n      Spark-on-Kubernetes - for scale-out data engineering and machine learning with seamless\\n      distributed dependency management. \\n\\n\\nSessions enable Data Scientists to directly leverage the CPU, memory,\\n          and GPU compute available across the workspace, while also being directly connected to the\\n          data in the data lake.\\n\\n\\nExperiments enable Data Scientists to run multiple variations of model\\n          training workloads, tracking the results of each Experiment in order to train the best\\n          possible Model.\\n\\n\\nModels can be deployed in a matter of clicks, removing any roadblocks to\\n          production. They are served as REST endpoints in a high availability manner, with\\n          automated lineage building and metric tracking for MLOps purposes.\\n\\n\\nJobs can be used to orchestrate an entire end-to-end automated pipeline,\\n          including monitoring for model drift and automatically kicking off model re-training and\\n          re-deployment as needed. \\n\\n\\nApplications deliver interactive experiences for business users in a\\n          matter of clicks. Frameworks such as Flask and Shiny can be used in development of these\\n          Applications, while Cloudera Data Visualization is also available as a point-and-click\\n          interface for building these experiences.\\n\\n\\n\\n\\n\\n\\n\\nCloudera Machine Learning benefits\\nThis section details the Cloudera Machine Learning benefits for each type of\\n    user.\\nCloudera Machine Learning is built for the agility and power of cloud\\n      computing, but is not limited to any one provider or data source. It is a comprehensive\\n      platform to collaboratively build and deploy machine learning capabilities at scale. \\nCloudera Machine Learning provides benefits for each type of user.\\nData Scientists\\n\\n\\nEnable DS teams to collaborate and speed model development and delivery with\\n          transparent, secure, and governed workflows\\n\\n\\nExpand AI use cases with automated ML pipelines and an integrated and complete\\n          production ML toolkit \\n\\n\\nEmpower faster decision making and trust with end-to-end visibility and\\n          auditability of data, processes, models, and dashboards\\n\\n\\nIT\\n\\n\\nIncrease DS productivity with visibility, security, and governance of the\\n          complete ML lifecycle \\n\\n\\nEliminate silos, blindspots, and the need to move/duplicate data with a fully\\n          integrated platform across the data lifecycle. \\n\\n\\nAccelerate AI with self-service access and containerized ML workspaces that\\n          remove the heavy lifting and get models to production faster \\n\\n\\nBusiness Users\\n\\n\\nAccess interactive Applications built and deployed by DS teams.\\n\\n\\nBe empowered with predictive insights to more intelligently make business\\n          decisions.\\n\\n\\n\\n\\nKey differences between Cloudera Machine Learning (Public Cloud) and Cloudera Data Science\\n    Workbench\\nThis topic highlights some key differences between Cloudera Data Science Workbench and\\n    its cloud-native counterpart, Cloudera Machine Learning. \\nHow is Cloudera Machine Learning (CML) related to Cloudera Data Science\\n        Workbench (CDSW)?\\nCML expands the end-to-end workflow of Cloudera Data Science\\n      Workbench (CDSW) with cloud-native benefits like rapid provisioning,\\n      elastic autoscaling, distributed dependency isolation, and distributed GPU\\n      training.\\nIt can run its own native distributed computing workloads without requiring a\\n      separate CDH cluster for scale-out compute. It is designed to run on CDP in existing\\n      Kubernetes environments, reducing operational costs for some customers while delivering\\n      multi-cloud portability. On Public Cloud, managed cloud Kubernetes services include EKS, AKS,\\n      or GKE, and on Private Cloud, they include Red Hat OpenShift or ECS (Embedded Container\\n      Service).\\nBoth products help data engineers and data science teams be more\\n      productive on shared data and compute, with strong security and\\n      governance. They share extensive code.\\nThere is one primary difference:\\n\\nCDSW extends an existing CDH cluster, by running on\\n            gateway nodes and pushing distributed compute workloads to the\\n            cluster. CDSW requires and supports a single CDH cluster for its\\n            distributed compute, including Apache Spark.\\n\\n\\nIn contrast, CML is self-contained and manages its own\\n            distributed compute, natively running workloads - including but not\\n            limited to Apache Spark - in containers on Kubernetes.\\nNote: It can still connect to an existing cluster to\\n            leverage its distributed compute, data, or metadata (SDX).\\n\\n\\nTable 1. Key Differences\\n\\n\\nCDSW\\nCML\\n\\n\\n\\nArchitecture\\n\\nCDSW can run on a  CDP-DC, CDH (5 or 6), and HDP cluster and runs on\\n                  one or more dedicated gateway nodes on the cluster. \\n\\n\\nCML is self-contained and does not require an\\n                  attached CDH/HDP cluster. \\n\\n\\n\\n\\nNotion of 1 master and multiple worker hosts. \\nNo designated master and worker hosts; all nodes\\n                are ephemeral. \\n\\n\\nSecurity\\nKerberos authentication integrated via the\\n                CDH/HDP cluster\\nCentralised identity management\\n                using FreeIPA via the Cloudera Data Platform (CDP).\\n\\n\\n\\nExternal authentication via LDAP/SAML.\\n\\n\\nApp Storage\\nProject files, internal postgresDB, and Livelog,\\n                are all stored persistently on the Master host. \\nAll required persistent storage is on\\n                cloud-managed block store, NFS, and a  relational data store.\\n                For example, for AWS, this is managed via EFS. \\n\\n\\nCompute\\nPython/R/Scala workloads run on the CDSW\\n                gateway nodes of the cluster. \\nPython/R/Scala workloads run on the\\n                CDP/cloud-provider-managed K8s cluster. \\n\\n\\n\\n\\nCDSW pushes distributed compute workloads, such as\\n                  Spark-on-YARN, to the CDH/HDP cluster. \\n\\nSpark-on-YARN is not supported; Spark-on-K8s\\n                instead. Workloads will run on a dedicated K8s cluster\\n                provisioned within the customer environment. \\n\\n\\n\\nNo autoscaling. \\nAutoscaling via your cloud service provider.\\n                Kubernetes/node-level autoscaling will be used to\\n                expand/contract the cluster size based on demand. \\n\\n\\nPackaging\\nAvailable as a downloadable RPM and CSD. \\nAvailable as a managed service on CDP.\\n\\n\\n\\nSpark is packaged with CDH.\\nSpark on K8s is packaged with CML - no dependency\\n                on an external cluster.\\n\\n\\nData Access\\nData usually resides on the attached CDH/HDP\\n                cluster in HDFS, Hive, HBase, and so on. \\nData can reside on object storage such as S3 or\\n                any pre-existing workload clusters registered with CDP. \\n\\n\\n\\n\"]]}\n"
     ]
    }
   ],
   "source": [
    "## Query Chroma vector DB \n",
    "## This query returns the two most similar results from a semantic search\n",
    "results = collection.query(\n",
    "    query_texts=[\"What is Apache Iceberg?\"],\n",
    "    n_results=2\n",
    "    # where={\"metadata_field\": \"is_equal_to_this\"}, # optional filter\n",
    "    # where_document={\"$contains\":\"search_string\"}  # optional filter\n",
    ")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4ac300",
   "metadata": {},
   "source": [
    "#### 5.9 Outcomes of using Chroma to map to the original file in the local file system (the complete file)\n",
    "\n",
    "This code defines a helper function load_context_chunk_from_data to retrieve the content of a knowledge base document based on its file path (ID), and then it iterates through the search results to print information about each result, including file path, classification, the snippet of the document, and the full document content loaded from the file, providing a detailed display of the search results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c30e5a6a-265b-4fa6-ae37-f5f38fe6296c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------- RESULT 1 ----------------\n",
      "\n",
      "FILE PATH: /home/cdsw/data/https:/docs.cloudera.com/machine-learning/cloud/architecture-overview/topics/ml-architecture-overview-cml.txt\n",
      "CLASSIFICATION: public\n",
      "DOCUMENT: CML ArchitectureCloudera Docs\n",
      "CML Architecture\n",
      "Once a CML workspace is provisioned, you can start using Cloudera Machine Learning\n",
      "      (CML) for your end-to-end Machine Learning workflow. \n",
      "CML is a three-tier application that consists of a presentation tier, an application tier\n",
      "         and a data tier. \n",
      "Web tier\n",
      "CML is a web application that provides a UI that simplifies the action of managing\n",
      "            workloads and resources for data scientists. It offers users a convenient way to deploy\n",
      "            and scale their analytical pipeline and collaborate with their colleagues in a secure\n",
      "            compartmentalized environment. \n",
      "CML communicates using HTTPS, Websocket, and gRPC. External communication is limited to\n",
      "            HTTP and Websocket for the web UI and APIs. In-cluster service-to-service communication\n",
      "            uses gRPC and is encrypted and mutually authenticated using TLS (Transport Layer\n",
      "            Security). \n",
      "\n",
      "Application tier\n",
      "The application tier uses an actual set of workloads that users are running. These\n",
      "            workloads are isolated in Kubernetes namespaces and run on specially marked compute\n",
      "            nodes. Kubernetes/node level auto scaling is used to expand/contract the cluster size\n",
      "            based on user demand.\n",
      "User code gets baked into Docker images via a set of Source-to-Image pods (S2I), which\n",
      "            includes a managing server, a queue for builds, a registry that serves the images for\n",
      "            Docker, a git server, and the builders that actually perform the image building.\n",
      "            Traditionally these images used the host machine's docker, but CML switched to\n",
      "            in-container builds for security and compliance on some platforms. \n",
      "\n",
      "Data tier\n",
      "CML uses an internal Postgres database for persisting metadata of user workloads such as\n",
      "            Sessions, Jobs, Models and Applications, which runs as a pod and is backed by a\n",
      "            persistent volume, using the cloud-provider's block storage offering (for example, EBS\n",
      "            for AWS and Premium_LRS for Azure). \n",
      "CML uses an NFS server, i.e. a POSIX-compliant file system, for storing users’ project\n",
      "            files, which include user code, libraries installed into a Session, and small data\n",
      "            files. For AWS, CML creates an Elastic File System (EFS) file system when provisioning\n",
      "            the workspace for storing project files. For Azure, users can either provide an NFS\n",
      "            volume created in Azure NetApp Files or an external NFS server when provisioning CML\n",
      "            workspaces for storing project files. This NFS server is supplied to the CML workspaces\n",
      "            as Kubernetes Persistent Volumes (PVs). Persistent Volume Claims (PVCs) are set up\n",
      "            per-namespace, and each user gets their own namespace - thus each user’s view of the NFS\n",
      "            server is limited to that exposed by the PVC. \n",
      "\n",
      "\n",
      "Parent topic: Architecture Overview\n",
      "\n",
      "FULL DOCUMENT (FROM FILE): CML ArchitectureCloudera Docs\n",
      "CML Architecture\n",
      "Once a CML workspace is provisioned, you can start using Cloudera Machine Learning\n",
      "      (CML) for your end-to-end Machine Learning workflow. \n",
      "CML is a three-tier application that consists of a presentation tier, an application tier\n",
      "         and a data tier. \n",
      "Web tier\n",
      "CML is a web application that provides a UI that simplifies the action of managing\n",
      "            workloads and resources for data scientists. It offers users a convenient way to deploy\n",
      "            and scale their analytical pipeline and collaborate with their colleagues in a secure\n",
      "            compartmentalized environment. \n",
      "CML communicates using HTTPS, Websocket, and gRPC. External communication is limited to\n",
      "            HTTP and Websocket for the web UI and APIs. In-cluster service-to-service communication\n",
      "            uses gRPC and is encrypted and mutually authenticated using TLS (Transport Layer\n",
      "            Security). \n",
      "\n",
      "Application tier\n",
      "The application tier uses an actual set of workloads that users are running. These\n",
      "            workloads are isolated in Kubernetes namespaces and run on specially marked compute\n",
      "            nodes. Kubernetes/node level auto scaling is used to expand/contract the cluster size\n",
      "            based on user demand.\n",
      "User code gets baked into Docker images via a set of Source-to-Image pods (S2I), which\n",
      "            includes a managing server, a queue for builds, a registry that serves the images for\n",
      "            Docker, a git server, and the builders that actually perform the image building.\n",
      "            Traditionally these images used the host machine's docker, but CML switched to\n",
      "            in-container builds for security and compliance on some platforms. \n",
      "\n",
      "Data tier\n",
      "CML uses an internal Postgres database for persisting metadata of user workloads such as\n",
      "            Sessions, Jobs, Models and Applications, which runs as a pod and is backed by a\n",
      "            persistent volume, using the cloud-provider's block storage offering (for example, EBS\n",
      "            for AWS and Premium_LRS for Azure). \n",
      "CML uses an NFS server, i.e. a POSIX-compliant file system, for storing users’ project\n",
      "            files, which include user code, libraries installed into a Session, and small data\n",
      "            files. For AWS, CML creates an Elastic File System (EFS) file system when provisioning\n",
      "            the workspace for storing project files. For Azure, users can either provide an NFS\n",
      "            volume created in Azure NetApp Files or an external NFS server when provisioning CML\n",
      "            workspaces for storing project files. This NFS server is supplied to the CML workspaces\n",
      "            as Kubernetes Persistent Volumes (PVs). Persistent Volume Claims (PVCs) are set up\n",
      "            per-namespace, and each user gets their own namespace - thus each user’s view of the NFS\n",
      "            server is limited to that exposed by the PVC. \n",
      "\n",
      "\n",
      "Parent topic: Architecture Overview\n",
      "\n",
      "------------- RESULT 2 ----------------\n",
      "\n",
      "FILE PATH: /home/cdsw/data/https:/docs.cloudera.com/machine-learning/cloud/product/topics/ml-product-overview.txt\n",
      "CLASSIFICATION: public\n",
      "DOCUMENT: Cloudera Machine Learning or CML Overview\n",
      "CML is an abbreviation for Cloudera Machine Learning \n",
      "\n",
      "Cloudera Machine Learning overview\n",
      "Machine learning has become one of the most critical capabilities for modern businesses\n",
      "    to grow and stay competitive today. From automating internal processes to optimizing the design,\n",
      "    creation, and marketing processes behind virtually every product consumed, ML models have\n",
      "    permeated almost every aspect of our work and personal lives.\n",
      "ML development is iterative and complex, made even harder because most ML tools aren’t built\n",
      "      for the entire machine learning lifecycle. Cloudera Machine Learning on\n",
      "      Cloudera Data Platform accelerates time-to-value by enabling data scientists to collaborate in\n",
      "      a single unified platform that is all inclusive for powering any AI use case. Purpose-built\n",
      "      for agile experimentation and production ML workflows, Cloudera Machine Learning manages everything from data preparation to MLOps,\n",
      "      to predictive reporting. Solve mission critical ML challenges along the entire lifecycle with\n",
      "      greater speed and agility to discover opportunities which can mean the difference for your\n",
      "      business.\n",
      "Each ML workspace enables teams of data scientists to develop, test, train, and ultimately\n",
      "      deploy machine learning models for building predictive applications all on the data under\n",
      "      management within the enterprise data cloud. ML workspaces support fully-containerized\n",
      "      execution of Python, R, Scala, and Spark workloads through flexible and extensible engines. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "AI applications\n",
      "Analytical Applications provide a place to host long running applications within a CML\n",
      "    project.\n",
      "While CML offers a place for Data Scientists to perform advanced analytics and models into\n",
      "      production, Analytical Applications provides a place to host long running applications within\n",
      "      a CML project. This opens up a larger group of users to the insights discovered in CML.\n",
      "      Applications can be built with a variety of frameworks like Flask and Streamlit. They run\n",
      "      within their own isolated compute instance which keeps them from timing out and they take\n",
      "      advantage of ML Runtimes. Applications are accessible to users through the web. Applications\n",
      "      can be for a variety of use cases like hosting interactive data visualizations or providing a\n",
      "      UI frontend for a deployed mode in CML. \n",
      "\n",
      "\n",
      "Exploratory Data Science\n",
      "CML enables data practitioners to discover, query, and easily visualize their data sets\n",
      "    all within a single user interface.\n",
      "The beginning of every data science project begins with finding and understanding the data\n",
      "      you need. CML brings all the tools you need for exploratory data analysis together in a single\n",
      "      UI so that data practitioners don't have to jump between applications, and IT doesn't have to\n",
      "      support multiple tools. CML provides users with a view of available data assets that they can\n",
      "      connect to, a sql editor to query those data sources, and an easy-to-use drag-and-drop\n",
      "      visualization tool to understand your data and communicate insights.\n",
      "\n",
      "\n",
      "ML Ops\n",
      "CML enables users to deploy machine learning and other models into\n",
      "    production.\n",
      "CML enables users to deploy machine learning and other models into production, either as a\n",
      "      batch process through the Jobs functionality, or as near-real-time REST APIs using the Models\n",
      "      functionality. In addition, CML provides a number of features to help maintain, monitor and\n",
      "      govern these models in production. The Model Governance feature ensures that every deployed\n",
      "      Model is tracked in the Cloudera Data Catalog, and allows the user to specify which data\n",
      "      tables were used to train the model in order to provide model-data lineage. Deployed Models\n",
      "      have a built-in dashboard for monitoring technical metrics relating to deployed CML Models,\n",
      "      such as request throughput, latency, and resource consumption. Additionally, users can track\n",
      "      arbitrary business metrics relating to each inference event, and match the results with\n",
      "      delayed metrics from a data warehouse or other source using an automatically generated UUID.\n",
      "      By analyzing these metrics, the user can assess the model for aggregated metrics such as\n",
      "      accuracy on an ongoing basis.\n",
      "\n",
      "\n",
      "Core capabilities\n",
      "This section details the core capabilities for Cloudera Machine Learning.\n",
      "Cloudera Machine Learning covers the end-to-end machine learning workflow,\n",
      "      enabling fully isolated and containerized workloads - including Python, R, and\n",
      "      Spark-on-Kubernetes - for scale-out data engineering and machine learning with seamless\n",
      "      distributed dependency management. \n",
      "\n",
      "\n",
      "Sessions enable Data Scientists to directly leverage the CPU, memory,\n",
      "          and GPU compute available across the workspace, while also being directly connected to the\n",
      "          data in the data lake.\n",
      "\n",
      "\n",
      "Experiments enable Data Scientists to run multiple variations of model\n",
      "          training workloads, tracking the results of each Experiment in order to train the best\n",
      "          possible Model.\n",
      "\n",
      "\n",
      "Models can be deployed in a matter of clicks, removing any roadblocks to\n",
      "          production. They are served as REST endpoints in a high availability manner, with\n",
      "          automated lineage building and metric tracking for MLOps purposes.\n",
      "\n",
      "\n",
      "Jobs can be used to orchestrate an entire end-to-end automated pipeline,\n",
      "          including monitoring for model drift and automatically kicking off model re-training and\n",
      "          re-deployment as needed. \n",
      "\n",
      "\n",
      "Applications deliver interactive experiences for business users in a\n",
      "          matter of clicks. Frameworks such as Flask and Shiny can be used in development of these\n",
      "          Applications, while Cloudera Data Visualization is also available as a point-and-click\n",
      "          interface for building these experiences.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Cloudera Machine Learning benefits\n",
      "This section details the Cloudera Machine Learning benefits for each type of\n",
      "    user.\n",
      "Cloudera Machine Learning is built for the agility and power of cloud\n",
      "      computing, but is not limited to any one provider or data source. It is a comprehensive\n",
      "      platform to collaboratively build and deploy machine learning capabilities at scale. \n",
      "Cloudera Machine Learning provides benefits for each type of user.\n",
      "Data Scientists\n",
      "\n",
      "\n",
      "Enable DS teams to collaborate and speed model development and delivery with\n",
      "          transparent, secure, and governed workflows\n",
      "\n",
      "\n",
      "Expand AI use cases with automated ML pipelines and an integrated and complete\n",
      "          production ML toolkit \n",
      "\n",
      "\n",
      "Empower faster decision making and trust with end-to-end visibility and\n",
      "          auditability of data, processes, models, and dashboards\n",
      "\n",
      "\n",
      "IT\n",
      "\n",
      "\n",
      "Increase DS productivity with visibility, security, and governance of the\n",
      "          complete ML lifecycle \n",
      "\n",
      "\n",
      "Eliminate silos, blindspots, and the need to move/duplicate data with a fully\n",
      "          integrated platform across the data lifecycle. \n",
      "\n",
      "\n",
      "Accelerate AI with self-service access and containerized ML workspaces that\n",
      "          remove the heavy lifting and get models to production faster \n",
      "\n",
      "\n",
      "Business Users\n",
      "\n",
      "\n",
      "Access interactive Applications built and deployed by DS teams.\n",
      "\n",
      "\n",
      "Be empowered with predictive insights to more intelligently make business\n",
      "          decisions.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Key differences between Cloudera Machine Learning (Public Cloud) and Cloudera Data Science\n",
      "    Workbench\n",
      "This topic highlights some key differences between Cloudera Data Science Workbench and\n",
      "    its cloud-native counterpart, Cloudera Machine Learning. \n",
      "How is Cloudera Machine Learning (CML) related to Cloudera Data Science\n",
      "        Workbench (CDSW)?\n",
      "CML expands the end-to-end workflow of Cloudera Data Science\n",
      "      Workbench (CDSW) with cloud-native benefits like rapid provisioning,\n",
      "      elastic autoscaling, distributed dependency isolation, and distributed GPU\n",
      "      training.\n",
      "It can run its own native distributed computing workloads without requiring a\n",
      "      separate CDH cluster for scale-out compute. It is designed to run on CDP in existing\n",
      "      Kubernetes environments, reducing operational costs for some customers while delivering\n",
      "      multi-cloud portability. On Public Cloud, managed cloud Kubernetes services include EKS, AKS,\n",
      "      or GKE, and on Private Cloud, they include Red Hat OpenShift or ECS (Embedded Container\n",
      "      Service).\n",
      "Both products help data engineers and data science teams be more\n",
      "      productive on shared data and compute, with strong security and\n",
      "      governance. They share extensive code.\n",
      "There is one primary difference:\n",
      "\n",
      "CDSW extends an existing CDH cluster, by running on\n",
      "            gateway nodes and pushing distributed compute workloads to the\n",
      "            cluster. CDSW requires and supports a single CDH cluster for its\n",
      "            distributed compute, including Apache Spark.\n",
      "\n",
      "\n",
      "In contrast, CML is self-contained and manages its own\n",
      "            distributed compute, natively running workloads - including but not\n",
      "            limited to Apache Spark - in containers on Kubernetes.\n",
      "Note: It can still connect to an existing cluster to\n",
      "            leverage its distributed compute, data, or metadata (SDX).\n",
      "\n",
      "\n",
      "Table 1. Key Differences\n",
      "\n",
      "\n",
      "CDSW\n",
      "CML\n",
      "\n",
      "\n",
      "\n",
      "Architecture\n",
      "\n",
      "CDSW can run on a  CDP-DC, CDH (5 or 6), and HDP cluster and runs on\n",
      "                  one or more dedicated gateway nodes on the cluster. \n",
      "\n",
      "\n",
      "CML is self-contained and does not require an\n",
      "                  attached CDH/HDP cluster. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Notion of 1 master and multiple worker hosts. \n",
      "No designated master and worker hosts; all nodes\n",
      "                are ephemeral. \n",
      "\n",
      "\n",
      "Security\n",
      "Kerberos authentication integrated via the\n",
      "                CDH/HDP cluster\n",
      "Centralised identity management\n",
      "                using FreeIPA via the Cloudera Data Platform (CDP).\n",
      "\n",
      "\n",
      "\n",
      "External authentication via LDAP/SAML.\n",
      "\n",
      "\n",
      "App Storage\n",
      "Project files, internal postgresDB, and Livelog,\n",
      "                are all stored persistently on the Master host. \n",
      "All required persistent storage is on\n",
      "                cloud-managed block store, NFS, and a  relational data store.\n",
      "                For example, for AWS, this is managed via EFS. \n",
      "\n",
      "\n",
      "Compute\n",
      "Python/R/Scala workloads run on the CDSW\n",
      "                gateway nodes of the cluster. \n",
      "Python/R/Scala workloads run on the\n",
      "                CDP/cloud-provider-managed K8s cluster. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "CDSW pushes distributed compute workloads, such as\n",
      "                  Spark-on-YARN, to the CDH/HDP cluster. \n",
      "\n",
      "Spark-on-YARN is not supported; Spark-on-K8s\n",
      "                instead. Workloads will run on a dedicated K8s cluster\n",
      "                provisioned within the customer environment. \n",
      "\n",
      "\n",
      "\n",
      "No autoscaling. \n",
      "Autoscaling via your cloud service provider.\n",
      "                Kubernetes/node-level autoscaling will be used to\n",
      "                expand/contract the cluster size based on demand. \n",
      "\n",
      "\n",
      "Packaging\n",
      "Available as a downloadable RPM and CSD. \n",
      "Available as a managed service on CDP.\n",
      "\n",
      "\n",
      "\n",
      "Spark is packaged with CDH.\n",
      "Spark on K8s is packaged with CML - no dependency\n",
      "                on an external cluster.\n",
      "\n",
      "\n",
      "Data Access\n",
      "Data usually resides on the attached CDH/HDP\n",
      "                cluster in HDFS, Hive, HBase, and so on. \n",
      "Data can reside on object storage such as S3 or\n",
      "                any pre-existing workload clusters registered with CDP. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "FULL DOCUMENT (FROM FILE): Cloudera Machine Learning or CML Overview\n",
      "CML is an abbreviation for Cloudera Machine Learning \n",
      "\n",
      "Cloudera Machine Learning overview\n",
      "Machine learning has become one of the most critical capabilities for modern businesses\n",
      "    to grow and stay competitive today. From automating internal processes to optimizing the design,\n",
      "    creation, and marketing processes behind virtually every product consumed, ML models have\n",
      "    permeated almost every aspect of our work and personal lives.\n",
      "ML development is iterative and complex, made even harder because most ML tools aren’t built\n",
      "      for the entire machine learning lifecycle. Cloudera Machine Learning on\n",
      "      Cloudera Data Platform accelerates time-to-value by enabling data scientists to collaborate in\n",
      "      a single unified platform that is all inclusive for powering any AI use case. Purpose-built\n",
      "      for agile experimentation and production ML workflows, Cloudera Machine Learning manages everything from data preparation to MLOps,\n",
      "      to predictive reporting. Solve mission critical ML challenges along the entire lifecycle with\n",
      "      greater speed and agility to discover opportunities which can mean the difference for your\n",
      "      business.\n",
      "Each ML workspace enables teams of data scientists to develop, test, train, and ultimately\n",
      "      deploy machine learning models for building predictive applications all on the data under\n",
      "      management within the enterprise data cloud. ML workspaces support fully-containerized\n",
      "      execution of Python, R, Scala, and Spark workloads through flexible and extensible engines. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "AI applications\n",
      "Analytical Applications provide a place to host long running applications within a CML\n",
      "    project.\n",
      "While CML offers a place for Data Scientists to perform advanced analytics and models into\n",
      "      production, Analytical Applications provides a place to host long running applications within\n",
      "      a CML project. This opens up a larger group of users to the insights discovered in CML.\n",
      "      Applications can be built with a variety of frameworks like Flask and Streamlit. They run\n",
      "      within their own isolated compute instance which keeps them from timing out and they take\n",
      "      advantage of ML Runtimes. Applications are accessible to users through the web. Applications\n",
      "      can be for a variety of use cases like hosting interactive data visualizations or providing a\n",
      "      UI frontend for a deployed mode in CML. \n",
      "\n",
      "\n",
      "Exploratory Data Science\n",
      "CML enables data practitioners to discover, query, and easily visualize their data sets\n",
      "    all within a single user interface.\n",
      "The beginning of every data science project begins with finding and understanding the data\n",
      "      you need. CML brings all the tools you need for exploratory data analysis together in a single\n",
      "      UI so that data practitioners don't have to jump between applications, and IT doesn't have to\n",
      "      support multiple tools. CML provides users with a view of available data assets that they can\n",
      "      connect to, a sql editor to query those data sources, and an easy-to-use drag-and-drop\n",
      "      visualization tool to understand your data and communicate insights.\n",
      "\n",
      "\n",
      "ML Ops\n",
      "CML enables users to deploy machine learning and other models into\n",
      "    production.\n",
      "CML enables users to deploy machine learning and other models into production, either as a\n",
      "      batch process through the Jobs functionality, or as near-real-time REST APIs using the Models\n",
      "      functionality. In addition, CML provides a number of features to help maintain, monitor and\n",
      "      govern these models in production. The Model Governance feature ensures that every deployed\n",
      "      Model is tracked in the Cloudera Data Catalog, and allows the user to specify which data\n",
      "      tables were used to train the model in order to provide model-data lineage. Deployed Models\n",
      "      have a built-in dashboard for monitoring technical metrics relating to deployed CML Models,\n",
      "      such as request throughput, latency, and resource consumption. Additionally, users can track\n",
      "      arbitrary business metrics relating to each inference event, and match the results with\n",
      "      delayed metrics from a data warehouse or other source using an automatically generated UUID.\n",
      "      By analyzing these metrics, the user can assess the model for aggregated metrics such as\n",
      "      accuracy on an ongoing basis.\n",
      "\n",
      "\n",
      "Core capabilities\n",
      "This section details the core capabilities for Cloudera Machine Learning.\n",
      "Cloudera Machine Learning covers the end-to-end machine learning workflow,\n",
      "      enabling fully isolated and containerized workloads - including Python, R, and\n",
      "      Spark-on-Kubernetes - for scale-out data engineering and machine learning with seamless\n",
      "      distributed dependency management. \n",
      "\n",
      "\n",
      "Sessions enable Data Scientists to directly leverage the CPU, memory,\n",
      "          and GPU compute available across the workspace, while also being directly connected to the\n",
      "          data in the data lake.\n",
      "\n",
      "\n",
      "Experiments enable Data Scientists to run multiple variations of model\n",
      "          training workloads, tracking the results of each Experiment in order to train the best\n",
      "          possible Model.\n",
      "\n",
      "\n",
      "Models can be deployed in a matter of clicks, removing any roadblocks to\n",
      "          production. They are served as REST endpoints in a high availability manner, with\n",
      "          automated lineage building and metric tracking for MLOps purposes.\n",
      "\n",
      "\n",
      "Jobs can be used to orchestrate an entire end-to-end automated pipeline,\n",
      "          including monitoring for model drift and automatically kicking off model re-training and\n",
      "          re-deployment as needed. \n",
      "\n",
      "\n",
      "Applications deliver interactive experiences for business users in a\n",
      "          matter of clicks. Frameworks such as Flask and Shiny can be used in development of these\n",
      "          Applications, while Cloudera Data Visualization is also available as a point-and-click\n",
      "          interface for building these experiences.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Cloudera Machine Learning benefits\n",
      "This section details the Cloudera Machine Learning benefits for each type of\n",
      "    user.\n",
      "Cloudera Machine Learning is built for the agility and power of cloud\n",
      "      computing, but is not limited to any one provider or data source. It is a comprehensive\n",
      "      platform to collaboratively build and deploy machine learning capabilities at scale. \n",
      "Cloudera Machine Learning provides benefits for each type of user.\n",
      "Data Scientists\n",
      "\n",
      "\n",
      "Enable DS teams to collaborate and speed model development and delivery with\n",
      "          transparent, secure, and governed workflows\n",
      "\n",
      "\n",
      "Expand AI use cases with automated ML pipelines and an integrated and complete\n",
      "          production ML toolkit \n",
      "\n",
      "\n",
      "Empower faster decision making and trust with end-to-end visibility and\n",
      "          auditability of data, processes, models, and dashboards\n",
      "\n",
      "\n",
      "IT\n",
      "\n",
      "\n",
      "Increase DS productivity with visibility, security, and governance of the\n",
      "          complete ML lifecycle \n",
      "\n",
      "\n",
      "Eliminate silos, blindspots, and the need to move/duplicate data with a fully\n",
      "          integrated platform across the data lifecycle. \n",
      "\n",
      "\n",
      "Accelerate AI with self-service access and containerized ML workspaces that\n",
      "          remove the heavy lifting and get models to production faster \n",
      "\n",
      "\n",
      "Business Users\n",
      "\n",
      "\n",
      "Access interactive Applications built and deployed by DS teams.\n",
      "\n",
      "\n",
      "Be empowered with predictive insights to more intelligently make business\n",
      "          decisions.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Key differences between Cloudera Machine Learning (Public Cloud) and Cloudera Data Science\n",
      "    Workbench\n",
      "This topic highlights some key differences between Cloudera Data Science Workbench and\n",
      "    its cloud-native counterpart, Cloudera Machine Learning. \n",
      "How is Cloudera Machine Learning (CML) related to Cloudera Data Science\n",
      "        Workbench (CDSW)?\n",
      "CML expands the end-to-end workflow of Cloudera Data Science\n",
      "      Workbench (CDSW) with cloud-native benefits like rapid provisioning,\n",
      "      elastic autoscaling, distributed dependency isolation, and distributed GPU\n",
      "      training.\n",
      "It can run its own native distributed computing workloads without requiring a\n",
      "      separate CDH cluster for scale-out compute. It is designed to run on CDP in existing\n",
      "      Kubernetes environments, reducing operational costs for some customers while delivering\n",
      "      multi-cloud portability. On Public Cloud, managed cloud Kubernetes services include EKS, AKS,\n",
      "      or GKE, and on Private Cloud, they include Red Hat OpenShift or ECS (Embedded Container\n",
      "      Service).\n",
      "Both products help data engineers and data science teams be more\n",
      "      productive on shared data and compute, with strong security and\n",
      "      governance. They share extensive code.\n",
      "There is one primary difference:\n",
      "\n",
      "CDSW extends an existing CDH cluster, by running on\n",
      "            gateway nodes and pushing distributed compute workloads to the\n",
      "            cluster. CDSW requires and supports a single CDH cluster for its\n",
      "            distributed compute, including Apache Spark.\n",
      "\n",
      "\n",
      "In contrast, CML is self-contained and manages its own\n",
      "            distributed compute, natively running workloads - including but not\n",
      "            limited to Apache Spark - in containers on Kubernetes.\n",
      "Note: It can still connect to an existing cluster to\n",
      "            leverage its distributed compute, data, or metadata (SDX).\n",
      "\n",
      "\n",
      "Table 1. Key Differences\n",
      "\n",
      "\n",
      "CDSW\n",
      "CML\n",
      "\n",
      "\n",
      "\n",
      "Architecture\n",
      "\n",
      "CDSW can run on a  CDP-DC, CDH (5 or 6), and HDP cluster and runs on\n",
      "                  one or more dedicated gateway nodes on the cluster. \n",
      "\n",
      "\n",
      "CML is self-contained and does not require an\n",
      "                  attached CDH/HDP cluster. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Notion of 1 master and multiple worker hosts. \n",
      "No designated master and worker hosts; all nodes\n",
      "                are ephemeral. \n",
      "\n",
      "\n",
      "Security\n",
      "Kerberos authentication integrated via the\n",
      "                CDH/HDP cluster\n",
      "Centralised identity management\n",
      "                using FreeIPA via the Cloudera Data Platform (CDP).\n",
      "\n",
      "\n",
      "\n",
      "External authentication via LDAP/SAML.\n",
      "\n",
      "\n",
      "App Storage\n",
      "Project files, internal postgresDB, and Livelog,\n",
      "                are all stored persistently on the Master host. \n",
      "All required persistent storage is on\n",
      "                cloud-managed block store, NFS, and a  relational data store.\n",
      "                For example, for AWS, this is managed via EFS. \n",
      "\n",
      "\n",
      "Compute\n",
      "Python/R/Scala workloads run on the CDSW\n",
      "                gateway nodes of the cluster. \n",
      "Python/R/Scala workloads run on the\n",
      "                CDP/cloud-provider-managed K8s cluster. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "CDSW pushes distributed compute workloads, such as\n",
      "                  Spark-on-YARN, to the CDH/HDP cluster. \n",
      "\n",
      "Spark-on-YARN is not supported; Spark-on-K8s\n",
      "                instead. Workloads will run on a dedicated K8s cluster\n",
      "                provisioned within the customer environment. \n",
      "\n",
      "\n",
      "\n",
      "No autoscaling. \n",
      "Autoscaling via your cloud service provider.\n",
      "                Kubernetes/node-level autoscaling will be used to\n",
      "                expand/contract the cluster size based on demand. \n",
      "\n",
      "\n",
      "Packaging\n",
      "Available as a downloadable RPM and CSD. \n",
      "Available as a managed service on CDP.\n",
      "\n",
      "\n",
      "\n",
      "Spark is packaged with CDH.\n",
      "Spark on K8s is packaged with CML - no dependency\n",
      "                on an external cluster.\n",
      "\n",
      "\n",
      "Data Access\n",
      "Data usually resides on the attached CDH/HDP\n",
      "                cluster in HDFS, Hive, HBase, and so on. \n",
      "Data can reside on object storage such as S3 or\n",
      "                any pre-existing workload clusters registered with CDP. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Helper function to return the Knowledge Base doc based on Knowledge Base ID (relative file path)\n",
    "def load_context_chunk_from_data(id_path):\n",
    "    with open(id_path, \"r\") as f: # Open file in read mode\n",
    "        return f.read()\n",
    "    \n",
    "## Clean up output and display full file\n",
    "for i in range(len(results['ids'][0])):\n",
    "    file_path = results['ids'][0][i]\n",
    "    classification = results['metadatas'][0][i]['classification']\n",
    "    document = results['documents'][0][i]\n",
    "    \n",
    "    print(\"------------- RESULT \" + str(i+1) + \" ----------------\\n\")\n",
    "    print(f\"FILE PATH: {file_path}\")\n",
    "    print(f\"CLASSIFICATION: {classification}\")\n",
    "    print(f\"DOCUMENT: {document}\\n\")\n",
    "    print(f\"FULL DOCUMENT (FROM FILE): {load_context_chunk_from_data(file_path)}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07d1bc4-8af6-470c-98b5-f65de15816e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
