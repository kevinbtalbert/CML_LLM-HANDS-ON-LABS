{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2. Use CML API to Define a Data Ingestion Job\n",
    "**TODO:** Highlight the advantages of programatic approach and add markdown cell before each code block below with a brief explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cmlapi\n",
    "import random\n",
    "import string\n",
    "import json\n",
    "\n",
    "if os.environ.get(\"PINECONE_API_KEY\") == \"\":\n",
    "    os.environ[\"PINECONE_API_KEY\"] = \"<YOUR-PINECONE-KEY>\"   # Replace this if running in your own environment\n",
    "\n",
    "if os.environ.get(\"PINECONE_ENVIRONMENT\") == \"\":\n",
    "    os.environ[\"PINECONE_ENVIRONMENT\"] = \"<YOUR-PINECONE-ENVT>\"   # Replace this if running in your own environment\n",
    "    \n",
    "if os.environ.get(\"PINECONE_INDEX\") == \"\":\n",
    "    os.environ[\"PINECONE_INDEX\"] = \"<YOUR-PINECONE-INDEX>\"   # Replace this if running in your own environment\n",
    "    \n",
    "client = cmlapi.default_client(url=os.getenv(\"CDSW_API_URL\").replace(\"/api/v1\", \"\"), cml_api_key=os.getenv(\"CDSW_APIV2_KEY\"))\n",
    "available_runtimes = client.list_runtimes(search_filter=json.dumps({\n",
    "    \"kernel\": \"Python 3.10\",\n",
    "    \"edition\": \"Nvidia GPU\",\n",
    "    \"editor\": \"JupyterLab\"\n",
    "}))\n",
    "print(available_runtimes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set available runtimes to the latest runtime in the environment (iterator is the number that begins with 0 and advances sequentially)\n",
    "## The JOB_IMAGE_ML_RUNTIME variable stores the ML Runtime which will be used to launch the job\n",
    "print(available_runtimes.runtimes[1])\n",
    "print(available_runtimes.runtimes[1].image_identifier)\n",
    "JOB_IMAGE_ML_RUNTIME = available_runtimes.runtimes[1].image_identifier\n",
    "\n",
    "## Store the ML Runtime for any future jobs in an environment variable so we don't have to do this step again\n",
    "os.environ['JOB_IMAGE_ML_RUNTIME'] = JOB_IMAGE_ML_RUNTIME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the current working project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'created_at': datetime.datetime(2023, 12, 11, 17, 36, 11, 602406, tzinfo=tzlocal()),\n",
      " 'creation_status': 'success',\n",
      " 'creator': {'email': 'ktalbert@cloudera.com',\n",
      "             'name': 'Kevin Talbert',\n",
      "             'username': 'ktalbert'},\n",
      " 'default_engine_type': 'ml_runtime',\n",
      " 'description': '',\n",
      " 'environment': '{\"CDSW_APP_POLLING_ENDPOINT\":\"/\",\"PROJECT_OWNER\":\"ktalbert\"}',\n",
      " 'ephemeral_storage_limit': 10,\n",
      " 'ephemeral_storage_request': 0,\n",
      " 'id': 'i7c6-5g66-06pw-iu5i',\n",
      " 'name': 'CML-LLM-HOL-Workshop',\n",
      " 'owner': {'email': 'ktalbert@cloudera.com',\n",
      "           'name': 'Kevin Talbert',\n",
      "           'username': 'ktalbert'},\n",
      " 'permissions': {'admin': True,\n",
      "                 'business_user': True,\n",
      "                 'inherit': False,\n",
      "                 'operator': True,\n",
      "                 'read': True,\n",
      "                 'write': True},\n",
      " 'shared_memory_limit': 0,\n",
      " 'updated_at': datetime.datetime(2023, 12, 11, 18, 27, 54, 4162, tzinfo=tzlocal()),\n",
      " 'visibility': 'private'}\n"
     ]
    }
   ],
   "source": [
    "project = client.get_project(project_id=os.getenv(\"CDSW_PROJECT_ID\"))\n",
    "print(project)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create and Run Job to Populate Pinecone Vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "random_id=''.join(random.choice(string.ascii_lowercase) for i in range(10))\n",
    "job_body = cmlapi.CreateJobRequest(\n",
    "    project_id = project.id,\n",
    "    name = \"Populate Pinecone Vector DB \" + random_id, \n",
    "    kernel = \"python3\", \n",
    "    script = \"3a_load_to_pinecone_vector_db/pinecone_vectordb_insert.py\",\n",
    "    cpu = 1,\n",
    "    memory = 4,\n",
    "    runtime_identifier = os.getenv('JOB_IMAGE_ML_RUNTIME')\n",
    ")\n",
    "\n",
    "job_result = client.create_job(\n",
    "    body = job_body, \n",
    "    project_id = str(project.id)\n",
    ")\n",
    "\n",
    "job_run = client.create_job_run(\n",
    "    cmlapi.CreateJobRunRequest(),\n",
    "    project_id = project.id, \n",
    "    job_id = job_result.id\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
